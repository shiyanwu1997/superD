#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯æ—¥å¿—åˆ†é¡µåŠ è½½ä¿®å¤æ•ˆæœ
åŠŸèƒ½ï¼š
1. æ¨¡æ‹Ÿå‰ç«¯æ—¥å¿—åˆ†é¡µåŠ è½½åŠŸèƒ½
2. éªŒè¯ä¿®å¤åçš„åç§»é‡è®¡ç®—æ˜¯å¦æ­£ç¡®
3. æ£€æŸ¥æ—¥å¿—æ˜¯å¦å­˜åœ¨é‡å¤æˆ–ç¼ºæ¼
"""

import xmlrpc.client
import re
import urllib.parse

# Supervisorè¿æ¥ä¿¡æ¯
SUPERVISOR_HOST = "lb-dhoa2qv6-huedfymo7wbtk2pa.clb.ap-singapore.tencentclb.com"
SUPERVISOR_PORT = 9000
SUPERVISOR_USER = "supervisor"
SUPERVISOR_PASS = "C*3#E^*Kz@ggUM!EDMBQUC@xhLWGuzGbF6$KG"
PROGRAM_NAME = "axdev_api_queue_market"

# æ—¥å¿—ç›¸å…³å‚æ•°
PAGE_SIZE = 100  # æ¯é¡µæ—¥å¿—è¡Œæ•°
MAX_LINES_PER_REQUEST = 50000  # æ¯æ¬¡è¯·æ±‚çš„æœ€å¤§å­—èŠ‚æ•°
TEST_PAGES = 3  # æµ‹è¯•çš„é¡µæ•°


def connect_supervisor():
    """è¿æ¥Supervisor API"""
    try:
        # æ­£ç¡®ç¼–ç URL
        encoded_pass = urllib.parse.quote(SUPERVISOR_PASS)
        url = f"http://{SUPERVISOR_USER}:{encoded_pass}@{SUPERVISOR_HOST}:{SUPERVISOR_PORT}/RPC2"
        
        proxy = xmlrpc.client.ServerProxy(url)
        # æµ‹è¯•è¿æ¥
        proxy.supervisor.getAPIVersion()
        print("âœ… æˆåŠŸè¿æ¥åˆ°Supervisor API")
        return proxy
    except Exception as e:
        print(f"âŒ è¿æ¥Supervisorå¤±è´¥: {e}")
        return None


def get_latest_logs(proxy, program_name, lines=100):
    """è·å–æœ€æ–°çš„æ—¥å¿—è¡Œï¼ˆæ¨¡æ‹Ÿå‰ç«¯åˆå§‹åŠ è½½ï¼‰"""
    try:
        print(f"\nğŸ“¥ è·å–æœ€æ–°æ—¥å¿—: program_name='{program_name}', lines={lines}")
        
        # ä½¿ç”¨tailProcessStdoutLogä»æ–‡ä»¶æœ«å°¾è·å–æ—¥å¿—
        result = proxy.supervisor.tailProcessStdoutLog(program_name, 0, MAX_LINES_PER_REQUEST)
        
        # è§£æç»“æœ
        logs = result[0]
        new_offset = result[1]
        
        # å°†æ—¥å¿—æŒ‰è¡Œåˆ†å‰²
        log_lines = [line.strip() for line in logs.strip().split('\n') if line.strip()]
        
        # åªè¿”å›æœ€ålinesè¡Œ
        latest_lines = log_lines[-lines:] if len(log_lines) > lines else log_lines
        
        print(f"   æ—¥å¿—è¡Œæ•°: {len(latest_lines)} (æ€»: {len(log_lines)})")
        print(f"   æœ€æ—©æ—¶é—´: {latest_lines[0][:23] if latest_lines else 'N/A'}")
        print(f"   æœ€æ™šæ—¶é—´: {latest_lines[-1][:23] if latest_lines else 'N/A'}")
        print(f"   æ–°åç§»é‡: {new_offset}")
        
        return latest_lines, new_offset
    except Exception as e:
        print(f"âŒ è·å–æœ€æ–°æ—¥å¿—å¤±è´¥: {e}")
        return [], 0


def get_historical_logs(proxy, program_name, offset, lines=100):
    """è·å–å†å²æ—¥å¿—ï¼ˆæ¨¡æ‹Ÿç‚¹å‡»"ç»§ç»­æŸ¥çœ‹å†å²æ—¥å¿—"ï¼‰"""
    try:
        # æ¨¡æ‹Ÿåç«¯çš„åç§»é‡è®¡ç®—é€»è¾‘
        average_line_size = 100
        read_length = lines * average_line_size
        actual_length = min(read_length, MAX_LINES_PER_REQUEST)
        actual_offset = max(0, offset - actual_length)
        
        print(f"\nğŸ“¥ è·å–å†å²æ—¥å¿—: program_name='{program_name}', offset={offset}, actual_offset={actual_offset}, read_length={read_length}")
        
        # ä½¿ç”¨readProcessStdoutLogä»æŒ‡å®šåç§»é‡è¯»å–å†å²æ—¥å¿—
        logs = proxy.supervisor.readProcessStdoutLog(program_name, actual_offset, actual_length)
        
        # åˆ†å‰²æ—¥å¿—è¡Œä¸ºæ•°ç»„
        log_lines = [line.strip() for line in logs.strip().split('\n') if line.strip()]
        
        # é™åˆ¶è¿”å›çš„è¡Œæ•°
        historical_lines = log_lines[:lines] if len(log_lines) > lines else log_lines
        
        print(f"   æ—¥å¿—è¡Œæ•°: {len(historical_lines)} (æ€»: {len(log_lines)})")
        print(f"   æœ€æ—©æ—¶é—´: {historical_lines[0][:23] if historical_lines else 'N/A'}")
        print(f"   æœ€æ™šæ—¶é—´: {historical_lines[-1][:23] if historical_lines else 'N/A'}")
        print(f"   è¿”å›åç§»é‡: {actual_offset}")
        
        return historical_lines, actual_offset
    except Exception as e:
        print(f"âŒ è·å–å†å²æ—¥å¿—å¤±è´¥: {e}")
        return [], offset


def check_duplicates(log_lists):
    """æ£€æŸ¥å¤šä¸ªæ—¥å¿—åˆ—è¡¨ä¸­æ˜¯å¦å­˜åœ¨é‡å¤æ—¥å¿—"""
    print("\nğŸ” æ£€æŸ¥æ—¥å¿—é‡å¤é—®é¢˜:")
    print("-" * 60)
    
    # åˆå¹¶æ‰€æœ‰æ—¥å¿—è¡Œ
    all_lines = []
    for i, log_list in enumerate(log_lists):
        all_lines.extend(log_list)
        print(f"   ç¬¬{i+1}é¡µ: {len(log_list)} è¡Œ")
    
    # æ£€æŸ¥é‡å¤
    unique_lines = set(all_lines)
    duplicate_count = len(all_lines) - len(unique_lines)
    
    if duplicate_count > 0:
        print(f"âŒ å‘ç° {duplicate_count} è¡Œé‡å¤æ—¥å¿—")
        return False
    else:
        print(f"âœ… æœªå‘ç°é‡å¤æ—¥å¿— (å…± {len(all_lines)} è¡Œ)")
        return True


def check_log_sequence(log_lists):
    """æ£€æŸ¥æ—¥å¿—çš„æ—¶é—´é¡ºåºæ˜¯å¦æ­£ç¡®"""
    print("\nğŸ“Š æ£€æŸ¥æ—¥å¿—æ—¶é—´é¡ºåº:")
    print("-" * 60)
    
    # åˆå¹¶æ‰€æœ‰æ—¥å¿—è¡Œ
    all_lines = []
    for log_list in log_lists:
        all_lines.extend(log_list)
    
    if len(all_lines) < 2:
        print("   æ—¥å¿—è¡Œå¤ªå°‘ï¼Œæ— æ³•æ£€æŸ¥é¡ºåº")
        return True
    
    # æ­£åˆ™è¡¨è¾¾å¼ï¼šåŒ¹é…æ—¥å¿—æ—¶é—´æˆ³
    time_pattern = re.compile(r'^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3})')
    
    # æ£€æŸ¥æ—¶é—´é¡ºåº
    prev_time = None
    out_of_order_count = 0
    
    for i, line in enumerate(all_lines):
        match = time_pattern.match(line)
        if match:
            current_time = match.group(1)
            
            if prev_time and current_time < prev_time:
                out_of_order_count += 1
                if out_of_order_count <= 3:  # åªæ‰“å°å‰3ä¸ªé—®é¢˜
                    print(f"   è¡Œ {i+1}: æ—¶é—´é¡ºåºé”™è¯¯")
                    print(f"      å½“å‰æ—¶é—´: {current_time}")
                    print(f"      å‰ä¸€æ—¶é—´: {prev_time}")
                    print(f"      è¡Œå†…å®¹: {line[:100]}...")
            
            prev_time = current_time
    
    if out_of_order_count > 0:
        print(f"âŒ å‘ç° {out_of_order_count} è¡Œæ—¶é—´é¡ºåºé”™è¯¯")
        return False
    else:
        print(f"âœ… æ‰€æœ‰æ—¥å¿—æŒ‰æ—¶é—´é¡ºåºæ­£ç¡®æ’åˆ—")
        return True


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("æµ‹è¯•æ—¥å¿—åˆ†é¡µåŠ è½½ä¿®å¤æ•ˆæœ")
    print("=" * 60)
    
    # è¿æ¥Supervisor
    proxy = connect_supervisor()
    if not proxy:
        return
    
    # 1. è·å–æœ€æ–°æ—¥å¿—ï¼ˆæ¨¡æ‹Ÿåˆå§‹åŠ è½½ï¼‰
    print("\n1. åˆå§‹åŠ è½½æœ€æ–°æ—¥å¿—")
    print("-" * 40)
    latest_logs, current_offset = get_latest_logs(proxy, PROGRAM_NAME, PAGE_SIZE)
    
    if not latest_logs:
        return
    
    # 2. è·å–å†å²æ—¥å¿—ï¼ˆæ¨¡æ‹Ÿç‚¹å‡»"ç»§ç»­æŸ¥çœ‹å†å²æ—¥å¿—"æŒ‰é’®ï¼‰
    print("\n2. æ¨¡æ‹Ÿç‚¹å‡»'ç»§ç»­æŸ¥çœ‹å†å²æ—¥å¿—'æŒ‰é’®")
    print("-" * 40)
    
    all_log_lists = [latest_logs]
    
    for attempt in range(1, TEST_PAGES + 1):
        print(f"\n{'-' * 40}")
        print(f"ç¬¬ {attempt} æ¬¡ç‚¹å‡»")
        print(f"{'-' * 40}")
        
        historical_logs, current_offset = get_historical_logs(proxy, PROGRAM_NAME, current_offset, PAGE_SIZE)
        
        if historical_logs:
            all_log_lists.append(historical_logs)
            print(f"   ç´¯è®¡æ—¥å¿—é¡µæ•°: {len(all_log_lists)}")
            print(f"   ç´¯è®¡æ—¥å¿—è¡Œæ•°: {sum(len(lst) for lst in all_log_lists)}")
        else:
            print(f"   ç¬¬ {attempt} æ¬¡è·å–å†å²æ—¥å¿—å¤±è´¥")
            break
    
    # 3. éªŒè¯ç»“æœ
    print("\n3. éªŒè¯ä¿®å¤æ•ˆæœ")
    print("-" * 40)
    
    # æ£€æŸ¥é‡å¤
    no_duplicates = check_duplicates(all_log_lists)
    
    # æ£€æŸ¥é¡ºåº
    correct_order = check_log_sequence(all_log_lists)
    
    # 4. æ€»ç»“
    print("\n4. æ€»ç»“")
    print("-" * 40)
    
    if no_duplicates and correct_order:
        print("âœ… ä¿®å¤æˆåŠŸï¼")
        print("   - æ—¥å¿—åˆ†é¡µåŠ è½½åŠŸèƒ½æ­£å¸¸")
        print("   - æ²¡æœ‰å‘ç°é‡å¤æ—¥å¿—")
        print("   - æ—¥å¿—æŒ‰æ—¶é—´é¡ºåºæ­£ç¡®æ’åˆ—")
    else:
        print("âŒ ä¿®å¤ä»æœ‰é—®é¢˜ï¼")
        if not no_duplicates:
            print("   - å‘ç°é‡å¤æ—¥å¿—")
        if not correct_order:
            print("   - æ—¥å¿—é¡ºåºé”™è¯¯")
    
    print(f"\nğŸ“Š æµ‹è¯•ç»Ÿè®¡ï¼š")
    print(f"   - æµ‹è¯•é¡µæ•°: {len(all_log_lists)}")
    print(f"   - æ€»æ—¥å¿—è¡Œæ•°: {sum(len(lst) for lst in all_log_lists)}")
    print(f"   - æœ€ååç§»é‡: {current_offset}")


if __name__ == "__main__":
    main()
